<!doctype html>
<html lang="ja">
<head prefix="og: http://ogp.me/ns#">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<title>PRML輪読会 3章4節 - Heavy Watal</title>
<link rel="stylesheet" href="/css/style.css">
<link rel="icon" href="/heavywatal.svg">
<link rel="icon" href="/favicon.png" sizes="32x32">
<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#eeeeee">
<meta name="author" content="Watal M. Iwasaki">
<meta property="og:title" content="PRML輪読会 3章4節">
<meta property="og:type" content="article">
<meta property="og:url" content="https://heavywatal.github.io/lectures/prml-3-4.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/heavywatal">
<meta property="og:description" content="">
<meta property="og:site_name" content="Heavy Watal">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@heavywatal">
<meta name="twitter:creator" content="@heavywatal">
<link rel="stylesheet" href="/lib/katex/katex.min.css">
<script src="/lib/katex/katex.min.js"></script>
<script type="application/ld+json">{
"@context": "http://schema.org",
"@type": "BreadcrumbList",
"itemListElement": [
 {"@type": "ListItem",
  "position": 1,
  "item": {"@id":"https://heavywatal.github.io/lectures.html","name":"lectures"} },
 {"@type": "ListItem",
  "position": 2,
  "item": {"@id":"https://heavywatal.github.io/lectures/prml-3-4.html","name":"PRML輪読会 3章4節"} }
]}</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-V60H2JH0G6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-V60H2JH0G6');
</script>
</head>
<body>
<header><a href="/">
<img class="logo" src="/heavywatal.svg" alt="岩嵜航">
Heavy Watal
</a>
</header>
<main>
<article>
<header><h1><a href="/lectures/prml-3-4.html">
PRML輪読会 3章4節
</a></h1>
<nav class="tags">
<a href="/tags/math.html"><div>math</div></a>
<a href="/tags/book.html"><div>book</div></a>
</nav>
</header>

<dl>
<dt>Author</dt>
<dd>Christopher M. Bishop</dd>
<dt>Book</dt>
<dd><a href="https://www.amazon.co.jp/dp/0387310738?&amp;linkCode=ll1&amp;tag=heavywatal-22&amp;linkId=0dacd1cec1bcc3d73dc0a9f27d158183">Pattern Recognition and Machine Learning</a></dd>
<dd><a href="https://www.amazon.co.jp/dp/4621061224?&amp;linkCode=ll1&amp;tag=heavywatal-22&amp;linkId=07bf2a676e8cf9d3f62a5ae847fa4962">パターン認識と機械学習 上</a></dd>
<dd><a href="https://www.amazon.co.jp/dp/4621061240?&amp;linkCode=ll1&amp;tag=heavywatal-22&amp;linkId=c376a10b53faed6da45c3591d5dbc61a">パターン認識と機械学習 下</a></dd>
<dt>Publisher</dt>
<dd><a href="http://www.springer.com/computer/image+processing/book/978-0-387-31073-2">Springer</a></dd>
<dt>Materials</dt>
<dd><a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/">http://research.microsoft.com/en-us/um/people/cmbishop/prml/</a></dd>
<dt>輪読担当</dt>
<dd>岩嵜航</dd>
<dt>日程</dt>
<dd>2014-06-30</dd>
</dl>
<h2 id="3-linear-models-for-regression">3. Linear Models For Regression</h2>
<p>3.1 Linear Basis Function Models: 八島さん、関口さん</p>
<p>3.2 The Bias-Variance Decomposition: チャッキーさん</p>
<p>3.3 Bayesian Linear Regression: 佐伯さん、永田さん</p>
<h3 id="34-bayesian-model-comparison">3.4 Bayesian Model Comparison</h3>
<p>最尤推定における過学習の問題 → 点推定じゃなくて周辺化することで回避しよう</p>
<ul>
<li>訓練データだけでモデルを比較できる (確認データ不要)</li>
<li>すべてのデータを訓練に使うことができる (cross-validation不要)</li>
<li>複雑性のパラメータも含めて同時に決められる e.g. <em>relevance vector machine</em> (Chapter 7)</li>
</ul>
<p>モデルの不確実さを確率で表し、加法定理・乗法定理を駆使して評価しよう</p>
<div>\[\begin{aligned}
p(X)   &= \sum^Y p(X,Y) \\
p(X,Y) &= p(Y \mid X) P(X)
\end{aligned}\]</div>
<div class="note">
<p>変数</p>
<p>新しい入力: $\mathbf x$<br>
それに対する出力(予測したい): $t$<br>
モデルの中のパラメータ: $\mathbf w$<br>
観察(トレーニング)データ: $\mathcal D$<br>
<em>L</em> 個のモデル: $\mathcal M_1, &hellip;, \mathcal M_L$</p>
</div>
<hr>
<p>モデルの事後分布 $p(\mathcal M _i \mid \mathcal D)$ は、</p>
<ul>
<li>$p(\mathcal M _i)$: どのモデルがアリかなという好み(事前分布)と、</li>
<li>$p(\mathcal D \mid \mathcal M _i)$:
そのモデルの下での観察データの出やすさ
(<em>model evidence</em>; <em>marginal likelihood</em> <strong>周辺尤度</strong>)</li>
</ul>
<p>の積に比例する (<strong>式 3.66</strong>)。</p>
<div>\[
p(\mathcal M _i \mid \mathcal D)
   \propto p(\mathcal M _i) p(\mathcal D \mid \mathcal M _i)
\]</div>
<p>これを評価したいんだけど、
モデルの事前分布なんてだいたい分からないので、重要なのは後者のevidence。</p>
<div class="note">
<p><em>Bayes factor</em> <strong>ベイズ因子</strong></p>
<p>モデル $\mathcal M _j$ に対する $\mathcal M _i$ のevidence比
$\frac {p(\mathcal D \mid \mathcal M _i)} {p(\mathcal D \mid \mathcal M _j)}$</p>
</div>
<hr>
<p><strong>Mixture distribution</strong></p>
<p>モデルの事後分布が分かれば予測分布 <em>predictive distribution</em>
(新しい $\mathbf x$ に対して $t$ がどんな値となるか)
も加法定理と乗法定理より導かれる (<strong>式 3.67</strong>)</p>
<div>\[\begin{aligned}
p(t \mid \mathbf x, \mathcal D)
   &= \sum _{i=1} ^L p(t, \mathcal M _i \mid \mathbf x, \mathcal D) \\
   &= \sum _{i=1} ^L {p(t \mid \mathbf x, \mathcal M _i, \mathcal D) p(\mathcal M _i \mid \mathcal D)}
\end{aligned}\]</div>
<p>これは、それぞれのモデルでの予測分布(入力に対してどういう出力になりそうか)を
事後分布(どのモデルっぽいか)で重み付けした平均した、混合分布。</p>
<p>例えば L=2 でモデルの片方の予測が $t = a$ らへんの鋭いピーク、
もう片方のモデルの予測が $t = b$ らへんの鋭いピークだった場合、
混合分布の予測はその中点 $t = (a + b) / 2$ にピークを持つのではなく、二山になってしまう。</p>
<hr>
<p><strong>Model selection</strong></p>
<p>パラメータセット $w$ を持つモデル $\mathcal M_i$
のevidenceをまた加法定理と乗法定理でばらしてみると (<strong>式 3.68</strong>)</p>
<div>\[\begin{aligned}
p(\mathcal D \mid \mathcal M _i)
   &= \int p(\mathcal D, \mathbf w \mid \mathcal M _i) \mathrm d \mathbf w \\
   &= \int p(\mathcal D \mid \mathbf w, \mathcal M _i) p(\mathbf w \mid \mathcal M _i) \mathrm d \mathbf w
\end{aligned}\]</div>
<p>パラメータセットの尤度をその確率分布で重み付けして積分したもの、
ってことで周辺尤度と呼ばれるのが納得できる。
また、そのモデルからデータセットが生成される確率
(ただしパラメータは事前分布からランダムに取ったもの) とも理解できる。
この $p(\mathbf w \mid \mathcal M_i)$
はモデルで想定してる何らかの事前分布ってことでいいのかな？</p>
<div class="note">
<p>積分の中身からすると、パラメータの事後分布を求める式の正規化項になる (<strong>式 3.69</strong>)</p>
<div>\[
p(\mathbf w \mid \mathcal D, \mathcal M _i)
   = \frac {p(\mathcal D \mid \mathbf w, \mathcal M _i) p(\mathbf w \mid \mathcal M _i)}
           {p(\mathcal D \mid \mathcal M _i)}
\]</div>
</div>
<p>あるひとつのパラメータ $w$ を持つモデルを考える。</p>
<div class="note">
<p><a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/prmlfigs-png/Figure3.12.png">Figure 3.12</a> 近似</p>
<p><img src="http://research.microsoft.com/en-us/um/people/cmbishop/prml/prmlfigs-png/Figure3.12.png" alt="Figure 3.12" width="300px"></p>
パラメータ $w$ の事前分布(青)と、それよりシャープな事後分布(赤)。
MAP推定値らへんで長方形に分布してるものとして近似。
</div>
<p><a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/prmlfigs-png/Figure3.12.png">Figure 3.12</a> のように近似すると式3.68の積分をただの掛け算で書き変えられる
(モデル依存の表記を省略, <strong>式 3.70, 3.71</strong>)。</p>
<div>\[\begin{aligned}
p(\mathcal D)
   &= \int p(\mathcal D \mid w) p (w) \mathrm dw \\
   &\simeq \frac 1 {\Delta w _\text{prior}} \int p(\mathcal D \mid w) \mathrm dw \\
   &\simeq \frac 1 {\Delta w _\text{prior}}
           p(\mathcal D \mid w _\text{MAP}) \Delta w _\text{posterior} \\
   &= p(\mathcal D \mid w _\text{MAP}) \frac {\Delta w _\text{posterior}}
                                             {\Delta w _\text{prior}} \\
\ln p(\mathcal D)
   &\simeq \ln p(\mathcal D \mid w _\text{MAP})
         + \ln \left( \frac {\Delta w _\text{posterior}} {\Delta w _\text{prior}} \right)
\end{aligned}\]</div>
<p>第一項は一番いいパラメータの当てはまりの良さ、
第二項はモデルの複雑性によるペナルティ
(事後分布の幅が狭くなるほど大きな負になる)。</p>
<p>$M$ 個のパラメータを持つモデルを考える。
事前分布と事後分布の幅の比が全てのパラメータで等しいとすると (<strong>式 3.72</strong>)</p>
<div>\[\begin{aligned}
p(\mathcal D)
   &= p(\mathcal D \mid w _\text{MAP}) \left(\frac {\Delta w _\text{posterior}}
                                                   {\Delta w _\text{prior}} \right)^M \\
\ln p(\mathcal D)
   &\simeq \ln p(\mathcal D \mid w _\text{MAP})
         + M \ln \left( \frac {\Delta w _\text{posterior}} {\Delta w _\text{prior}} \right)
\end{aligned}\]</div>
<p>パラメータが増える(モデルの複雑性が増す)ごとに第一項は大きくなっていくかもしれないが、
第二項のペナルティも大きな負になっていく。
<strong>中程度が良さそう → 過学習しない！</strong></p>
<div class="note">
<p>長方形じゃなくてもっとちゃんとしたGaussian近似をSection 4.4.1で</p>
</div>
<div class="note">
<p><a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/prmlfigs-png/Figure3.13.png">Figure 3.13</a> <strong>どうして中程度の複雑性のモデルが好まれるか</strong></p>
<p><img src="http://research.microsoft.com/en-us/um/people/cmbishop/prml/prmlfigs-png/Figure3.13.png" alt="Figure 3.13" width="300px"></p>
横軸はデータセットが取りうる値を1次元で表現。
モデルの複雑性を $\mathcal M _1 < \mathcal M _2 <  \mathcal M _3$ とする。
<p>シンプルなモデル $\mathcal M _1$ は生成(説明)できるデータの範囲が狭く
(いろいろパラメータを変えても似通ったデータセットしか出てこない)、
複雑なモデル $\mathcal M _3$ はいろんなデータを生成できるがそれぞれの重みは低い。
特定のデータセット $\mathcal D _0$ に対しては中程度の複雑さを持つモデル
$\mathcal M _2$ が一番大きいevidenceを持つことになる。</p>
</div>
<hr>
<p><strong>Expected Bayes factor</strong></p>
<p>$\mathcal M_1$ が真のモデルだとする。
ベイズ因子は個々のデータで見ると
正しくない $\mathcal M_2$ とかで大きくなる場合もあるが、
真の分布の上でを平均すると (<strong>式 3.73</strong>)</p>
<div>\[
\int p(\mathcal D \mid \mathcal M _1)
    \ln \frac {p(\mathcal D \mid \mathcal M _1)}
              {p(\mathcal D \mid \mathcal M _2)} \mathrm d \mathcal D
\]</div>
<p>で <em>Kullback-Leibler divergence</em> (Section 1.6.1 <strong>式 1.113</strong>)
と同じ形になり（対数の中身と符号を入れ替え）、
常に正（ただし2つの分布が等しい場合は0）の値をとることが分かっているので、
<strong>平均的には正しいモデルのベイズ因子が大きくなり、好まれる。</strong>
ただし、データを生成する真の分布が <em>L</em> 個のモデルの中に含まれてれば、の話。</p>
<hr>
<p><strong>まとめ</strong></p>
<ul>
<li>Bayesian frameworkでは過学習を避け、訓練データだけでモデル比較できる</li>
<li>でもモデルの形に関する仮定は必要で、それが正しくないと誤った結論を導きうる</li>
<li>結論は事前分布の特性にかなり依存
<ul>
<li>非正則事前分布では正規化定数が定義できないためevidenceを定義できない</li>
<li>じゃあ正則事前分布の極限(e.g. 分散∞の正規分布)をとればいいかというと、
それではevidenceが0に収束してしまう</li>
<li>先に2つのモデルのevidence比を取ってから極限をとるといいかも</li>
</ul>
</li>
<li>実際の応用では独立なテストデータを評価用に取っとくのが賢明 (←え、結局？)</li>
</ul>

</article>
</main>

<nav class="side-bar">
<div class="menu">

<div><a href="/about.html">About</a></div>

<div><a href="/research.html">Research Interests</a></div>

<input type="checkbox" id="menu-rstats">
<label for="menu-rstats">R stats</label>
<ul>
<li><a href="/rstats/intro.html">R自学自習の基礎知識</a></li>
<li><a href="/rstats/programming.html">RプログラミングTips</a></li>
<li><a href="/rstats/config.html">R環境設定</a></li>
<li><a href="/rstats/ggplot2.html">ggplot2</a></li>
<li><a href="/rstats/dplyr.html">dplyr</a></li>
<li><a href="/rstats/tidyr.html">tidyr</a></li>
<li><a href="/rstats/purrr.html">purrr</a></li>
<li><a href="/rstats/readr.html">readr</a></li>
<li><a href="/rstats/stringr.html">stringr</a></li>
<li><a href="/rstats/knitr.html">knitr</a></li>
<li><a href="/rstats/parallel.html">parallel</a></li>
<li><a href="/rstats/devtools.html">devtools</a></li>
<li><a href="/rstats/rcpp.html">Rcpp</a></li>
<li><a href="/rstats/bioconductor.html">Bioconductor</a></li>
<li><a href="/rstats/genomicranges.html">GenomicRanges</a></li>
<li><a href="/rstats/rtracklayer.html">rtracklayer</a></li>
<li><a href="/rstats/biomart.html">biomaRt</a></li>
<li><a href="/rstats/edger.html">edgeR</a></li>
<li><a href="/rstats/topgo.html">topGO</a></li>
<li><a href="/rstats/rgl.html">rgl</a></li>
<li><a href="/rstats/stan.html">Stan</a></li>
</ul>

<input type="checkbox" id="menu-python">
<label for="menu-python">Python</label>
<ul>
<li><a href="/python/install.html">Pythonインストール</a></li>
<li><a href="/python/pip.html">pip</a></li>
<li><a href="/python/ipython.html">IPython</a></li>
<li><a href="/python/biopython.html">BioPython</a></li>
<li><a href="/python/concurrent.html">concurrent.futures</a></li>
<li><a href="/python/copy.html">copy</a></li>
<li><a href="/python/matplotlib.html">matplotlib &#43; seaborn</a></li>
<li><a href="/python/scipy.html">NumPy, SciPy</a></li>
<li><a href="/python/pandas.html">Pandas</a></li>
<li><a href="/python/packaging.html">Pythonパッケージ作成</a></li>
</ul>

<input type="checkbox" id="menu-cxx">
<label for="menu-cxx">C&#43;&#43;</label>
<ul>
<li><a href="/cxx/boost.html">Boost</a></li>
<li><a href="/cxx/getopt.html">C&#43;&#43;コマンドライン引数</a></li>
<li><a href="/cxx/speed.html">C&#43;&#43;高速化</a></li>
<li><a href="/cxx/gcc.html">gcc</a></li>
<li><a href="/cxx/bitwise.html">ビット演算</a></li>
<li><a href="/cxx/random.html">擬似乱数生成器</a></li>
</ul>

<input type="checkbox" id="menu-bio">
<label for="menu-bio">Biology</label>
<ul>
<li><a href="/bio/blast.html">BLAST</a></li>
<li><a href="/bio/dadi.html">dadi</a></li>
<li><a href="/bio/gene_ontology.html">Gene Ontology</a></li>
<li><a href="/bio/meme.html">MEME</a></li>
<li><a href="/bio/popgen.html">Population Genetics</a></li>
<li><a href="/bio/repeatmasker.html">RepeatMasker</a></li>
<li><a href="/bio/samtools.html">SAMtools</a></li>
<li><a href="/bio/shirokane.html">SHIROKANE</a></li>
<li><a href="/bio/stochastic_process.html">Stochastic Process</a></li>
<li><a href="/bio/mathmorph.html">数理形態学</a></li>
<li><a href="/bio/linear_algebra.html">線形代数</a></li>
<li><a href="/bio/complexnetwork.html">複雑ネットワーク</a></li>
<li><a href="/bio/nig.html">遺伝研スパコン</a></li>
<li><a href="/bio/motif.html">配列モチーフ探索</a></li>
</ul>

<input type="checkbox" id="menu-dev">
<label for="menu-dev">Developer Tools</label>
<ul>
<li><a href="/dev/apptainer.html">Apptainer</a></li>
<li><a href="/dev/autotools.html">autoconf, automake</a></li>
<li><a href="/dev/cmake.html">CMake</a></li>
<li><a href="/dev/docker.html">Docker</a></li>
<li><a href="/dev/emacs.html">Emacs</a></li>
<li><a href="/dev/git.html">Git</a></li>
<li><a href="/dev/make.html">make</a></li>
<li><a href="/dev/mount.html">mount</a></li>
<li><a href="/dev/rsync.html">rsync</a></li>
<li><a href="/dev/ssh.html">ssh</a></li>
<li><a href="/dev/tmux.html">tmux</a></li>
<li><a href="/dev/torque.html">TORQUE</a></li>
<li><a href="/dev/vi.html">vi</a></li>
<li><a href="/dev/vscode.html">VSCode</a></li>
<li><a href="/dev/zsh.html">zsh</a></li>
<li><a href="/dev/sh.html">シェルスクリプト</a></li>
<li><a href="/dev/nohup.html">プロセス管理</a></li>
<li><a href="/dev/devenv.html">開発環境</a></li>
</ul>

<input type="checkbox" id="menu-mac">
<label for="menu-mac">Mac</label>
<ul>
<li><a href="/mac/applescript.html">AppleScript</a></li>
<li><a href="/mac/homebrew.html">Homebrew</a></li>
<li><a href="/mac/keyboard.html">Keyboard</a></li>
<li><a href="/mac/command.html">Mac固有コマンド</a></li>
<li><a href="/mac/quicklook.html">QuickLook</a></li>
<li><a href="/mac/winebottler.html">WineBottler</a></li>
</ul>

<input type="checkbox" id="menu-lectures" checked>
<label for="menu-lectures" class="active">Lectures</label>
<ul>
<li><a href="/lectures/verhoef_comm_ecol-11.html">Community Ecology 輪読会 11章</a></li>
<li><a href="/lectures/git2018nrifs.html">Git入門2018</a></li>
<li><a href="/lectures/git2019makino.html">Git入門2019</a></li>
<li><a href="/lectures/prml-11-1.html">PRML輪読会 11章1節</a></li>
<li><a href="/lectures/prml-2-1.html">PRML輪読会 2章前半</a></li>
<li class="active"><a href="/lectures/prml-3-4.html">PRML輪読会 3章4節</a></li>
<li><a href="/lectures/wakeley-2-2.html">Wakeley輪読会 2章2節</a></li>
</ul>

<input type="checkbox" id="menu-misc">
<label for="menu-misc">Miscellaneous</label>
<ul>
<li><a href="/misc/fonts.html">Fonts</a></li>
<li><a href="/misc/gollum.html">Gollum</a></li>
<li><a href="/misc/hugo.html">Hugo</a></li>
<li><a href="/misc/latex.html">LaTeX</a></li>
</ul>

<div><a href="/tags.html">Tags</a></div>
</div>
<form action="/search.html" id="search-form">
<input type="search" name="q" placeholder="search">
</form>
</nav>
<footer><small>(ɔ) 2008 岩嵜航 Watal M. Iwasaki</small></footer>
</body>
</html>
