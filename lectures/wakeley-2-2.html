<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.16-DEV" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="/css/theme.css">
<link rel="stylesheet" href="/css/highlight.css">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="icon" href="/favicon-192x192.png" sizes="192x192">
<link rel="apple-touch-icon" href="/favicon-192x192.png" sizes="192x192">
<title>Wakeley輪読会 2章2節 - Watal M. Iwasaki</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEnvironments: false,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for(i = 0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.classList.add('has-jax');
  }
});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-41178626-2', 'auto');
ga('send', 'pageview');
</script>
</head>
<body><div id="container">
<header><h1><a href="/">
<img class="logo" src="/favicon-32x32.png" alt="航">
Watal M. Iwasaki
</a></h1>
</header>

<main>
<article>
<header><h1><a href="">
Wakeley輪読会 2章2節
</a></h1>
<ul id="tags">
<li><a href="/tags/genetics">genetics</a></li>
<li><a href="/tags/book">book</a></li>
</ul>
</header>



<p><a href="http://www.amazon.co.jp/gp/product/0974707759/ref=as_li_ss_il?ie=UTF8&camp=247&creative=7399&creativeASIN=0974707759&linkCode=as2&tag=heavywatal-22"><img border="0" src="http://ws-fe.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=0974707759&Format=_SL250_&ID=AsinImage&MarketPlace=JP&ServiceVersion=20070822&WS=1&tag=heavywatal-22" ></a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=heavywatal-22&l=as2&o=9&a=0974707759" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /></p>

<dl>
<dt>Book</dt>
<dd><a href="http://www.amazon.co.jp/gp/product/0974707759/ref=as_li_ss_tl?ie=UTF8&amp;camp=247&amp;creative=7399&amp;creativeASIN=0974707759&amp;linkCode=as2&amp;tag=heavywatal-22">Coalescent Theory &mdash; An Introduction</a></dd>
<dt>Author</dt>
<dd><a href="http://www.oeb.harvard.edu/faculty/wakeley/wakeleylab.htm">John Wakeley</a></dd>
<dt>Publisher</dt>
<dd><a href="http://www.roberts-publishers.com/authors/wakeley-john/coalescent-theory.html">Roberts &amp; Company</a></dd>
<dt>Errata</dt>
<dd><a href="http://www.oeb.harvard.edu/faculty/wakeley/John/Reprints/CorrectionsWakeleyFall2010.pdf">PDF</a></dd>
<dt>輪読担当</dt>
<dd>岩嵜航</dd>
<dt>日程</dt>
<dd>2015-03-20</dd>
</dl>

<h2 id="2-probability-theory">2. Probability Theory</h2>

<h3 id="2-1-fundamentals">2.1 Fundamentals</h3>

<h4 id="2-1-1-events-probabilities-and-random-variables">2.1.1 Events, Probabilities, and Random Variables</h4>

<h4 id="2-1-2-probability-distributions">2.1.2 Probability Distributions</h4>

<h3 id="2-2-poisson-processes">2.2 Poisson Processes</h3>

<p>The backbone of the neutral coalescent:</p>

<dl>
<dt>Poisson distribution</dt>
<dd>the number of events that occur over a fixed period of time</dd>
<dt>Exponential distribution</dt>
<dd>waiting time until a first event occurs</dd>
</dl>

<hr />

<p>The poisson process is a counting process.</p>

<div>$$\begin{split}
P[K(t) = 1]   &= \lambda t + o(t) \\
P[K(t) \ge 2] &= o(t)
\end{split}$$</div>

<dl>
<dt>where</dt>
<dd>$K(t)$ is the number of observed events before $t$. $K(0) = 0$<br />
$\lambda$ is the rate of occurrence per unit time<br />
$o(t)$ goes to faster than $t$</dd>
<dt>These implies, within a sufficiently short period of time, $\delta t$,</dt>
<dd>$P[K(\delta t) = 1] \approx \lambda \delta t$<br />
$P[K(\delta t) \ge 2]$ is negligible (i.e., two events don&rsquo;t occur at the same time)</dd>
</dl>

<p>The number of events over time 0 to $t$
(or from arbitrary starting time $s$ to $s + t$) is Poisson distributed,
for $k = 0, 1, 2, &hellip;$,</p>

<div>$$\begin{split}
P[K(t) = k]          \;&=\; \frac {(\lambda t)^k} {k!} e^{-\lambda t} \\
P[K(t+s) - K(s) = k] \;&=\; P[K(t) = k]
\end{split}$$</div>

<p>(Eq. 2.53)
Waiting time to the first event is exponentially distiributed,</p>

<div>$$\begin{split}
f_T(t) = \lambda e^{-\lambda t}
\end{split}$$</div>

<dl>
<dt><em>memoryless</em> (<strong>無記憶性</strong>)</dt>
<dd>The number of coin-tosses required to observe the next heads is independent of previous results.<br />
The waiting times between successive events are <em>i.i.d.</em> (independent and identically distributed).</dd>
</dl>

<hr />

<p>(Eq. 2.54)
The waiting time $W$ until the $n$ th event
(= the sum of $n$ <em>i.i.d.</em> wating times)
can be derived by $n - 1$ successive convolutions:</p>

<div>$$\begin{split}
f_{W,1}(t) &= f_T(t) = \lambda e^{-\lambda t} \\
f_{W,2}(t) &= \int _0^t \lambda e^{-\lambda (t-t')} \; \lambda e^{-\lambda t'} dt' \\
           &= \lambda ^2 e^{-\lambda t} \Big[1\Big]_0^t \\
           &= t\lambda^2 e^{-\lambda t} \\
f_{W,3}(t) &= \int _0^t \lambda e^{-\lambda (t-t')} \; f_2(t') dt' \\
           &= \frac {t^2 \lambda^3 e^{-\lambda t}} {2!} \\
           &\;\vdots \\
f_{W,n}(t) &= \lambda e^{-\lambda t} \frac{(\lambda t)^{n-1}} {(n - 1)!}
\end{split}$$</div>

<p>This is the <strong>gamma distribution</strong>.</p>

<p>(Eq. 2.55)
The mean and the variance are</p>

<div>$$\begin{split}
\mathrm{E}[W] &= \sum^n \mathrm{E}[T] \\
              &= \sum^n \frac 1 \lambda \\
              &= \frac n \lambda \\
\mathrm{Var}[W] &= \sum^n \mathrm{Var}[T] \\
                &= \sum^n \frac 1 {\lambda^2} \\
                &= \frac n {\lambda^2}
\end{split}$$</div>

<p>These hold even when $n$ is not an integer
if we replace the factorial $(n - 1)!$ with <em>gamma function</em>,
$\Gamma(n) = \int^\infty_0 x^{n-1} e^{-x} dx$.
(Eq. 2.57)</p>

<hr />

<p>The coalescent considers the events
that have a very small probability of occurring in any single generation:</p>

<ul>
<li>coalescence (common ancestor event)</li>
<li>mutation</li>
<li>migration</li>
</ul>

<p>They will each form a Poisson process.</p>

<h4 id="2-2-1-poisson-process-results-for-the-coalescent">2.2.1 Poisson Process Results for the Coalescent</h4>

<h5 id="the-sum-of-independent-poissons">The Sum of Independent Poissons</h5>

<dl>
<dt>Two independent Poisson random variables:</dt>
<dd><code>$X_1$</code> with occurrence rate $\lambda _1$<br />
<code>$X_2$</code> with occurrence rate <code>$\lambda _2$</code></dd>
</dl>

<p>(Eq. 2.58)
The distribution of <code>$Y = X_1 + X_2$</code> can be obtained by convolution:</p>

<div>$$\begin{split}
P[Y=k] \;&=\; \sum _{i=0}^k P[X_1=i] \; P[X_2=k-i] \\
         &=\; \sum _{i=0}^k \frac {\lambda _1^i} {i!} e^{-\lambda _1}
                            \frac {\lambda _2^{k-i}} {(k-i)!} e^{-\lambda _2} \\
         &=\; e^{-\lambda _1} e^{-\lambda _2}
              \sum _{i=0}^k \frac {\lambda _1^i} {i!}
                            \frac {\lambda _2^{k-i}} {(k-i)!} \frac {k!}{k!} \\
         &=\; \frac {e^{-(\lambda _1 + \lambda _2)}} {k!}
              \sum _{i=0}^k {k \choose i} \lambda _1^i \lambda _2^{k-i} \\
         &=\; \frac {e^{-(\lambda _1 + \lambda _2)}} {k!} (\lambda _1 + \lambda _2)^k \\
         &=\; \text{Poisson distribution with occurrence rate } \lambda _1 + \lambda _2
\end{split}$$</div>

<p>The sum of independent Poisson processes is another Poisson process.</p>

<h5 id="the-probability-that-the-first-event-is-of-a-particular-type">The Probability that the First Event Is of a Particular Type</h5>

<p>(Eq 2.60)
The probability that <code>$X_1$</code> is observed before <code>$X_2$</code>
is given simply by the relative rate of the event
(i.e., as a fraction of the total rate):</p>

<div>$$\begin{split}
P[T_1 < T_2]
   &= \int _0^\infty P[T_2>t]\; f_{T_1}(t) dt \\
   &= \int _0^\infty \left(e^{-\lambda _2 t} \right)_\text{Eq. 2.59}\;
                     \lambda _1 e^{-\lambda _1 t} dt \\
   &= \lambda _1 \int _0^\infty e^{-(\lambda _1 + \lambda _2) t} dt \\
   &= \lambda _1 \left[-\frac {e^{-(\lambda _1 + \lambda _2)t}}
                             {\lambda _1 + \lambda _2} \right]_0^\infty \\
   &= \frac {\lambda _1} {\lambda _1 + \lambda _2},
\end{split}$$</div>

<p>using (Eq 2.59)</p>

<div>$$\begin{split}
P[T>t] \;&=\; \int _t^\infty \lambda e^{-\lambda t} dt \\
         &=\; \left[-e^{-\lambda t} \right]_t^\infty \\
         &=\; e^{-\lambda t}.
\end{split}$$</div>

<h5 id="the-time-to-the-first-event-among-independent-poissons">The Time to the First Event among Independent Poissons</h5>

<p>(Eq. 2.61)
The distribution of <code>$T = \min(T_1, T_2)$</code></p>

<div>$$\begin{split}
P[T>t] \;&=\; P[\min(T_1, T_2) > t] \\
         &=\; P[T_1 > t \;\cap\; T_2 > t] \\
         &=\; P[T_1 > t]\; P[T_2 > t] \\
         &=\; e^{-\lambda _1 t} e^{-\lambda _2 t} \\
         &=\; e^{-(\lambda _1 + \lambda _2) t}
\end{split}$$</div>

<p>Therefore, <code>$f_{\min(T_1,T_2)}(t) = (\lambda _1 + \lambda _2) e^{-(\lambda _2 + \lambda _1)t}$</code></p>

<p>There is a one-to-one correspondence between cumulative distribution $P[T \le t]$ and probability densities <code>$f_T(t)$</code></p>

<h5 id="the-number-of-events-required-to-see-a-particular-outcome">The Number of Events Required to See a Particular Outcome</h5>

<p>$X_2, X_2, X_2, &hellip;, X_2, \boldsymbol{X_1}$, &hellip;</p>

<p>(Eq. 2.62)
How many <code>$X_2$</code> (e.g., mutation events) occur
before <code>$X_1$</code> (e.g., common ancector event)?</p>

<div>$$\begin{split}
P[K=k] \;&=\; P[\text{First }X_1\text{ occurs at }K\text{th trial}] \\
         &=\; P[X_2\text{ occurs }k - 1\text{ times first, then }X_1\text{ occurs}] \\
         &=\; \left(\frac {\lambda _2} {\lambda _1 + \lambda _2} \right)^{k-1}
                    \frac {\lambda _1} {\lambda _1 + \lambda _2}
\end{split}$$</div>

<p>This is the <em>geometric distribution</em> with the rate
$p = \frac {\lambda _1} {\lambda _1 + \lambda _2}$.</p>

<p>The process is just like a series of <em>Bernoulli trials</em> with probability of success
$p = \frac {\lambda _1} {\lambda _1 + \lambda _2}$.</p>

<h5 id="tying-all-this-together-a-filtered-poisson-process">Tying All This Together: A Filtered Poisson Process</h5>

<p>Reinterpret <code>$f_T(t)$</code> with the sum rule and product rule
(see Eq. 2.7, 2.8).</p>

<div>$$\begin{split}
f_T(t)\; &=\; \sum _{k=1}^\infty f_T(t \mid K=k)\; P[K=k] \\
         &=\; \sum _{k=1}^\infty (\text{Eq. }2.54) (\text{Eq. }2.62) \\
         &=\; \sum _{k=1}^\infty
              (\lambda _1 + \lambda _2) e^{-(\lambda _1 + \lambda _2)t}
              \frac {\{(\lambda _1 + \lambda _2)t\}^{k-1}} {(k-1)!}\;
              \left(\frac {\lambda _2} {\lambda _1 + \lambda _2} \right)^{k-1}
                    \frac {\lambda _1} {\lambda _1 + \lambda _2} \\
         &=\; \lambda _1 e^{-(\lambda _1 + \lambda _2)t}\;
              \sum _{k=1}^\infty \frac {(\lambda _2 t)^{k-1}} {(k-1)!} \\
         &=\; \lambda _1 e^{-(\lambda _1 + \lambda _2)t}\;
              \sum _{k=0}^\infty \frac {(\lambda _2 t)^k} {k!} \\
         &=\; \lambda _1 e^{-(\lambda _1 + \lambda _2)t}\; e^{\lambda _2 t} \\
         &=\; \lambda _1 e^{-\lambda _1 t}
\end{split}$$</div>

<div class="note">
<p>Taylor series of $e^x$</p>

<div>$$\begin{split}
e^x \;&=\; 1 + \frac x 1 + \frac {x^2} {2!} + \frac {x^3} {3!} + \cdots \\
      &=\; \sum _{k=0}^\infty \frac {x^k} {k!}
\end{split}$$</div>

</div>


<dl>
<dt>Filtered Poisson process = Poisson process with rate <code>$\lambda p\; (=\lambda _1)$</code></dt>
<dd>-   total occurrence rate <code>$\lambda = \lambda _1 + \lambda _2$</code>

<ul>
<li>acceptance rate (proportion of the focal event)
<code>$p = \frac {\lambda _1} {\lambda _1 + \lambda _2}$</code></li>
</ul></dd>
</dl>

<h4 id="2-2-2-convolutions-of-exponential-distributions">2.2.2 Convolutions of Exponential Distributions</h4>

<p>The sum of the waiting times of $n$ events:</p>

<dl>
<dt>If the rate does not change with each event ($\lambda _i = \lambda \text{ for all } i$),</dt>
<dd>→ gamma-distributed (Eq. 2.54)</dd>
<dt>If the rate changes with each event ($\lambda _i \neq \lambda _j \text{ for } i \neq j$),</dt>
<dd>(e.g., in the study of genealogies, the rate of coalescence changes every time a coalescent event occurs)<br />
→ obtained by successive convolution of exponential distribution (Eq. 2.63, 2.64)</dd>
</dl>

<div>$$\begin{split}
f_{T_1 + T_2}(t)
   &= \int _0^t f_{T_1}(s)\; f_{T_2}(t-s)ds \\
   &= \int _0^t \lambda _1 e^{-\lambda _1 s}\; \lambda _2 e^{-\lambda _2 (t-s)}ds \\
   &= \lambda _1 \lambda _2 e^{-\lambda _2 t} \int _0^t e^{-(\lambda _1 -\lambda _2)s}ds \\
   &= \lambda _1 \lambda _2 e^{-\lambda _2 t}
      \left[-\frac 1{\lambda _1 - \lambda _2} e^{-(\lambda _1 -\lambda _2)s} \right]_0^t \\
   &= \frac {\lambda _1} {\lambda _1 - \lambda _2} \lambda _2 e^{-\lambda _2 t}
      \left(1 - e^{-(\lambda _1 -\lambda _2)t} \right) \\
   &= \frac {\lambda _1} {\lambda _1 - \lambda _2} \lambda _2 e^{-\lambda _2 t} +
      \frac {\lambda _2} {\lambda _2 - \lambda _1} \lambda _1 e^{-\lambda _1 t} \\
   &= \frac {\lambda _1} {\lambda _1 - \lambda _2} f_{T_2}(t) +
      \frac {\lambda _2} {\lambda _2 - \lambda _1} f_{T_1}(t) \\
  (&= \text{weighted sum of the original distributions})\\[1ex]
f_{T_1 + T_2 + T_3}(t)
   &= \int _0^t f_{T_1 + T_2}(s)\; f_{T_3}(t-s)ds \\
   &= \frac {\lambda _2} {\lambda _2 - \lambda _1}
      \frac {\lambda _3} {\lambda _3 - \lambda _1} \lambda _1 e^{-\lambda _1 t} +
      \frac {\lambda _3} {\lambda _3 - \lambda _2}
      \frac {\lambda _1} {\lambda _1 - \lambda _2} \lambda _2 e^{-\lambda _2 t} +
      \frac {\lambda _1} {\lambda _1 - \lambda _3}
      \frac {\lambda _2} {\lambda _2 - \lambda _3} \lambda _3 e^{-\lambda _3 t} \\[1ex]
f_{T_1 + T_2 + T_3 + T_4}(t) &= \cdots \\
   &\;\vdots \\
f_{\sum _{i=1}^n T_i}(t)
   &= \sum_{i=1}^n \lambda _i e^{-\lambda _i t}
      \prod _{j=1,\;j \neq i} \frac {\lambda _j} {\lambda _j - \lambda _i}
\end{split}$$</div>

<p>We will use this to obtain the distribution of the total waiting time
to the MRCA of the entire samples (Eq. 3.27)</p>

</article>
</main>

<nav id="menu">

<div ><a href="/cv.html">Curriculum Vitae</a></div>


<div ><a href="/research.html">Research Interests</a></div>


<input type="checkbox" id="R stats">
<label for="R stats">R stats</label>
<ul>
<li><a href="/rstats/bioconductor.html">Bioconductor</a></li>
<li><a href="/rstats/biomart.html">biomaRt</a></li>
<li><a href="/rstats/devtools.html">devtools</a></li>
<li><a href="/rstats/dplyr.html">dplyr</a></li>
<li><a href="/rstats/edger.html">edgeR</a></li>
<li><a href="/rstats/ggbio.html">ggbio</a></li>
<li><a href="/rstats/ggplot2.html">ggplot2</a></li>
<li><a href="/rstats/plyr.html">plyr</a></li>
<li><a href="/rstats/readr.html">readr</a></li>
<li><a href="/rstats/reshape2.html">reshape2</a></li>
<li><a href="/rstats/rgl.html">rgl</a></li>
<li><a href="/rstats/rjags.html">rjags</a></li>
<li><a href="/rstats/rtracklayer.html">rtracklayer</a></li>
<li><a href="/rstats/stringr.html">stringr</a></li>
<li><a href="/rstats/tidyr.html">tidyr</a></li>
<li><a href="/rstats/topgo.html">topGO</a></li>
<li><a href="/rstats/programming.html">プログラミングTips</a></li>
<li><a href="/rstats/config.html">環境設定</a></li>
<li><a href="/rstats/intro.html">自学自習のための基礎知識</a></li>
</ul>

<input type="checkbox" id="Python">
<label for="Python">Python</label>
<ul>
<li><a href="/python/biopython.html">BioPython</a></li>
<li><a href="/python/egglib.html">EggLib</a></li>
<li><a href="/python/ipython.html">IPython</a></li>
<li><a href="/python/install.html">Installation</a></li>
<li><a href="/python/scipy.html">NumPy, SciPy</a></li>
<li><a href="/python/pyqt.html">PyQt</a></li>
<li><a href="/python/copy.html">copy</a></li>
<li><a href="/python/matplotlib.html">matplotlib &#43; seaborn</a></li>
<li><a href="/python/pip.html">pip</a></li>
<li><a href="/python/rpy2.html">rpy2</a></li>
</ul>

<input type="checkbox" id="C&#43;&#43;">
<label for="C&#43;&#43;">C&#43;&#43;</label>
<ul>
<li><a href="/cxx/boost.html">Boost</a></li>
<li><a href="/cxx/getopt.html">C&#43;&#43; コマンドライン引数の取得</a></li>
<li><a href="/cxx/clang.html">clang / llvm</a></li>
<li><a href="/cxx/gcc.html">gcc</a></li>
<li><a href="/cxx/speed.html">めざせC&#43;&#43;高速プログラム</a></li>
<li><a href="/cxx/random.html">擬似乱数生成器</a></li>
</ul>

<input type="checkbox" id="Biology">
<label for="Biology">Biology</label>
<ul>
<li><a href="/bio/blast.html">BLAST</a></li>
<li><a href="/bio/dnasp.html">DnaSP</a></li>
<li><a href="/bio/emboss.html">EMBOSS</a></li>
<li><a href="/bio/ensembl.html">Ensembl</a></li>
<li><a href="/bio/gene_ontology.html">Gene Ontology</a></li>
<li><a href="/bio/meme.html">MEME</a></li>
<li><a href="/bio/mrbayes.html">MrBayes</a></li>
<li><a href="/bio/paml.html">PAML</a></li>
<li><a href="/bio/popgen.html">Population Genetics</a></li>
<li><a href="/bio/repeatmasker.html">RepeatMasker</a></li>
<li><a href="/bio/samtools.html">SAMtools</a></li>
<li><a href="/bio/stochastic_process.html">Stochastic Process</a></li>
<li><a href="/bio/dadi.html">dadi</a></li>
<li><a href="/bio/linear_algebra.html">線形代数</a></li>
<li><a href="/bio/complexnetwork.html">複雑ネットワーク</a></li>
<li><a href="/bio/nig.html">遺伝研スパコン</a></li>
<li><a href="/bio/motif.html">配列モチーフ探索</a></li>
</ul>

<input type="checkbox" id="Developer Tools">
<label for="Developer Tools">Developer Tools</label>
<ul>
<li><a href="/dev/etc.html">/etc</a></li>
<li><a href="/dev/emacs.html">Emacs</a></li>
<li><a href="/dev/mercurial.html">Mercurial</a></li>
<li><a href="/dev/mysql.html">MySQL</a></li>
<li><a href="/dev/qt.html">Qt</a></li>
<li><a href="/dev/sh.html">Shell Script</a></li>
<li><a href="/dev/torque.html">TORQUE</a></li>
<li><a href="/dev/tex.html">TeX</a></li>
<li><a href="/dev/autotools.html">autoconf, automake</a></li>
<li><a href="/dev/make.html">make</a></li>
<li><a href="/dev/mount.html">mount</a></li>
<li><a href="/dev/nano.html">nano</a></li>
<li><a href="/dev/rsync.html">rsync</a></li>
<li><a href="/dev/ssh.html">ssh</a></li>
<li><a href="/dev/sshfs.html">sshfs</a></li>
<li><a href="/dev/tmux.html">tmux</a></li>
<li><a href="/dev/zsh.html">zsh</a></li>
<li><a href="/dev/nohup.html">プロセス管理</a></li>
<li><a href="/dev/devenv.html">開発環境</a></li>
</ul>

<input type="checkbox" id="Linux">
<label for="Linux">Linux</label>
<ul>
<li><a href="/linux/centos.html">CentOS 6.5</a></li>
<li><a href="/linux/japanese.html">Linux日本語環境</a></li>
<li><a href="/linux/apt.html">apt/dpkg</a></li>
<li><a href="/linux/ufw.html">ufw</a></li>
</ul>

<input type="checkbox" id="Mac">
<label for="Mac">Mac</label>
<ul>
<li><a href="/mac/applescript.html">AppleScript</a></li>
<li><a href="/mac/homebrew.html">Homebrew</a></li>
<li><a href="/mac/keyboard.html">Keyboard</a></li>
<li><a href="/mac/command.html">Mac Command</a></li>
<li><a href="/mac/macports.html">MacPorts</a></li>
<li><a href="/mac/quicklook.html">QuickLook</a></li>
<li><a href="/mac/spotlight.html">Spotlight</a></li>
<li><a href="/mac/winebottler.html">WineBottler</a></li>
<li><a href="/mac/kotoeri.html">ことえり</a></li>
</ul>

<input type="checkbox" id="Lectures" checked>
<label for="Lectures" class="active">Lectures</label>
<ul>
<li><a href="/lectures/verhoef_comm_ecol-11.html">Community Ecology 輪読会 11章</a></li>
<li><a href="/lectures/prml-11-1.html">PRML輪読会 11章1節</a></li>
<li><a href="/lectures/prml-2-1.html">PRML輪読会 2章前半</a></li>
<li><a href="/lectures/prml-3-4.html">PRML輪読会 3章4節</a></li>
<li class="active"><a href="/lectures/wakeley-2-2.html">Wakeley輪読会 2章2節</a></li>
</ul>

<input type="checkbox" id="Miscellaneous">
<label for="Miscellaneous">Miscellaneous</label>
<ul>
<li><a href="/misc/fonts.html">Fonts</a></li>
<li><a href="/misc/mailman.html">Mailman</a></li>
<li><a href="/misc/vnc.html">VNCによる画面共有</a></li>
<li><a href="/misc/virtualbox.html">VirtualBox</a></li>
</ul>
</nav>


<aside>
<h1><label for="inputsource">Page source</label></h1>
<input type="checkbox" id="inputsource">
<pre id="pagesource"><code class="language-markdown">
+++
title = "Wakeley輪読会 2章2節"
+++

&lt;a href=&#34;http://www.amazon.co.jp/gp/product/0974707759/ref=as_li_ss_il?ie=UTF8&amp;camp=247&amp;creative=7399&amp;creativeASIN=0974707759&amp;linkCode=as2&amp;tag=heavywatal-22&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;http://ws-fe.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=0974707759&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=JP&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=heavywatal-22&#34; &gt;&lt;/a&gt;&lt;img src=&#34;http://ir-jp.amazon-adsystem.com/e/ir?t=heavywatal-22&amp;l=as2&amp;o=9&amp;a=0974707759&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;

Book
:   [Coalescent Theory --- An Introduction](http://www.amazon.co.jp/gp/product/0974707759/ref=as_li_ss_tl?ie=UTF8&amp;camp=247&amp;creative=7399&amp;creativeASIN=0974707759&amp;linkCode=as2&amp;tag=heavywatal-22)

Author
:   [John Wakeley](http://www.oeb.harvard.edu/faculty/wakeley/wakeleylab.htm)

Publisher
:   [Roberts &amp; Company](http://www.roberts-publishers.com/authors/wakeley-john/coalescent-theory.html)

Errata
:   [PDF](http://www.oeb.harvard.edu/faculty/wakeley/John/Reprints/CorrectionsWakeleyFall2010.pdf)

輪読担当
:   岩嵜航

日程
:   2015-03-20

## 2. Probability Theory

### 2.1 Fundamentals

#### 2.1.1 Events, Probabilities, and Random Variables

#### 2.1.2 Probability Distributions

### 2.2 Poisson Processes

The backbone of the neutral coalescent:

Poisson distribution
:   the number of events that occur over a fixed period of time

Exponential distribution
:   waiting time until a first event occurs

------------------------------------------------------------------------

The poisson process is a counting process.

&lt;div&gt;$$\begin{split}
P[K(t) = 1]   &amp;= \lambda t &#43; o(t) \\
P[K(t) \ge 2] &amp;= o(t)
\end{split}$$&lt;/div&gt;

where
:   $K(t)$ is the number of observed events before $t$. $K(0) = 0$\
    $\lambda$ is the rate of occurrence per unit time\
    $o(t)$ goes to faster than $t$

These implies, within a sufficiently short period of time, $\delta t$,
:   $P[K(\delta t) = 1] \approx \lambda \delta t$\
    $P[K(\delta t) \ge 2]$ is negligible (i.e., two events don&#39;t occur at the same time)

The number of events over time 0 to $t$
(or from arbitrary starting time $s$ to $s &#43; t$) is Poisson distributed,
for $k = 0, 1, 2, ...$,

&lt;div&gt;$$\begin{split}
P[K(t) = k]          \;&amp;=\; \frac {(\lambda t)^k} {k!} e^{-\lambda t} \\
P[K(t&#43;s) - K(s) = k] \;&amp;=\; P[K(t) = k]
\end{split}$$&lt;/div&gt;

(Eq. 2.53)
Waiting time to the first event is exponentially distiributed,

&lt;div&gt;$$\begin{split}
f_T(t) = \lambda e^{-\lambda t}
\end{split}$$&lt;/div&gt;

*memoryless* (**無記憶性**)
:   The number of coin-tosses required to observe the next heads is independent of previous results.\
    The waiting times between successive events are *i.i.d.* (independent and identically distributed).

------------------------------------------------------------------------

(Eq. 2.54)
The waiting time $W$ until the $n$ th event
(= the sum of $n$ *i.i.d.* wating times)
can be derived by $n - 1$ successive convolutions:

&lt;div&gt;$$\begin{split}
f_{W,1}(t) &amp;= f_T(t) = \lambda e^{-\lambda t} \\
f_{W,2}(t) &amp;= \int _0^t \lambda e^{-\lambda (t-t&#39;)} \; \lambda e^{-\lambda t&#39;} dt&#39; \\
           &amp;= \lambda ^2 e^{-\lambda t} \Big[1\Big]_0^t \\
           &amp;= t\lambda^2 e^{-\lambda t} \\
f_{W,3}(t) &amp;= \int _0^t \lambda e^{-\lambda (t-t&#39;)} \; f_2(t&#39;) dt&#39; \\
           &amp;= \frac {t^2 \lambda^3 e^{-\lambda t}} {2!} \\
           &amp;\;\vdots \\
f_{W,n}(t) &amp;= \lambda e^{-\lambda t} \frac{(\lambda t)^{n-1}} {(n - 1)!}
\end{split}$$&lt;/div&gt;

This is the **gamma distribution**.

(Eq. 2.55)
The mean and the variance are

&lt;div&gt;$$\begin{split}
\mathrm{E}[W] &amp;= \sum^n \mathrm{E}[T] \\
              &amp;= \sum^n \frac 1 \lambda \\
              &amp;= \frac n \lambda \\
\mathrm{Var}[W] &amp;= \sum^n \mathrm{Var}[T] \\
                &amp;= \sum^n \frac 1 {\lambda^2} \\
                &amp;= \frac n {\lambda^2}
\end{split}$$&lt;/div&gt;

These hold even when $n$ is not an integer
if we replace the factorial $(n - 1)!$ with *gamma function*,
$\Gamma(n) = \int^\infty_0 x^{n-1} e^{-x} dx$.
(Eq. 2.57)

------------------------------------------------------------------------

The coalescent considers the events
that have a very small probability of occurring in any single generation:

-   coalescence (common ancestor event)
-   mutation
-   migration

They will each form a Poisson process.

#### 2.2.1 Poisson Process Results for the Coalescent

##### The Sum of Independent Poissons

Two independent Poisson random variables:
:   `$X_1$` with occurrence rate $\lambda _1$\
    `$X_2$` with occurrence rate `$\lambda _2$`

(Eq. 2.58)
The distribution of `$Y = X_1 &#43; X_2$` can be obtained by convolution:

&lt;div&gt;$$\begin{split}
P[Y=k] \;&amp;=\; \sum _{i=0}^k P[X_1=i] \; P[X_2=k-i] \\
         &amp;=\; \sum _{i=0}^k \frac {\lambda _1^i} {i!} e^{-\lambda _1}
                            \frac {\lambda _2^{k-i}} {(k-i)!} e^{-\lambda _2} \\
         &amp;=\; e^{-\lambda _1} e^{-\lambda _2}
              \sum _{i=0}^k \frac {\lambda _1^i} {i!}
                            \frac {\lambda _2^{k-i}} {(k-i)!} \frac {k!}{k!} \\
         &amp;=\; \frac {e^{-(\lambda _1 &#43; \lambda _2)}} {k!}
              \sum _{i=0}^k {k \choose i} \lambda _1^i \lambda _2^{k-i} \\
         &amp;=\; \frac {e^{-(\lambda _1 &#43; \lambda _2)}} {k!} (\lambda _1 &#43; \lambda _2)^k \\
         &amp;=\; \text{Poisson distribution with occurrence rate } \lambda _1 &#43; \lambda _2
\end{split}$$&lt;/div&gt;

The sum of independent Poisson processes is another Poisson process.

##### The Probability that the First Event Is of a Particular Type

(Eq 2.60)
The probability that `$X_1$` is observed before `$X_2$`
is given simply by the relative rate of the event
(i.e., as a fraction of the total rate):

&lt;div&gt;$$\begin{split}
P[T_1 &lt; T_2]
   &amp;= \int _0^\infty P[T_2&gt;t]\; f_{T_1}(t) dt \\
   &amp;= \int _0^\infty \left(e^{-\lambda _2 t} \right)_\text{Eq. 2.59}\;
                     \lambda _1 e^{-\lambda _1 t} dt \\
   &amp;= \lambda _1 \int _0^\infty e^{-(\lambda _1 &#43; \lambda _2) t} dt \\
   &amp;= \lambda _1 \left[-\frac {e^{-(\lambda _1 &#43; \lambda _2)t}}
                             {\lambda _1 &#43; \lambda _2} \right]_0^\infty \\
   &amp;= \frac {\lambda _1} {\lambda _1 &#43; \lambda _2},
\end{split}$$&lt;/div&gt;

using (Eq 2.59)

&lt;div&gt;$$\begin{split}
P[T&gt;t] \;&amp;=\; \int _t^\infty \lambda e^{-\lambda t} dt \\
         &amp;=\; \left[-e^{-\lambda t} \right]_t^\infty \\
         &amp;=\; e^{-\lambda t}.
\end{split}$$&lt;/div&gt;

##### The Time to the First Event among Independent Poissons

(Eq. 2.61)
The distribution of `$T = \min(T_1, T_2)$`

&lt;div&gt;$$\begin{split}
P[T&gt;t] \;&amp;=\; P[\min(T_1, T_2) &gt; t] \\
         &amp;=\; P[T_1 &gt; t \;\cap\; T_2 &gt; t] \\
         &amp;=\; P[T_1 &gt; t]\; P[T_2 &gt; t] \\
         &amp;=\; e^{-\lambda _1 t} e^{-\lambda _2 t} \\
         &amp;=\; e^{-(\lambda _1 &#43; \lambda _2) t}
\end{split}$$&lt;/div&gt;

Therefore, `$f_{\min(T_1,T_2)}(t) = (\lambda _1 &#43; \lambda _2) e^{-(\lambda _2 &#43; \lambda _1)t}$`

There is a one-to-one correspondence between cumulative distribution $P[T \le t]$ and probability densities `$f_T(t)$`

##### The Number of Events Required to See a Particular Outcome

$X_2, X_2, X_2, ..., X_2, \boldsymbol{X_1}$, ...

(Eq. 2.62)
How many `$X_2$` (e.g., mutation events) occur
before `$X_1$` (e.g., common ancector event)?

&lt;div&gt;$$\begin{split}
P[K=k] \;&amp;=\; P[\text{First }X_1\text{ occurs at }K\text{th trial}] \\
         &amp;=\; P[X_2\text{ occurs }k - 1\text{ times first, then }X_1\text{ occurs}] \\
         &amp;=\; \left(\frac {\lambda _2} {\lambda _1 &#43; \lambda _2} \right)^{k-1}
                    \frac {\lambda _1} {\lambda _1 &#43; \lambda _2}
\end{split}$$&lt;/div&gt;

This is the *geometric distribution* with the rate
$p = \frac {\lambda _1} {\lambda _1 &#43; \lambda _2}$.

The process is just like a series of *Bernoulli trials* with probability of success
$p = \frac {\lambda _1} {\lambda _1 &#43; \lambda _2}$.

##### Tying All This Together: A Filtered Poisson Process

Reinterpret `$f_T(t)$` with the sum rule and product rule
(see Eq. 2.7, 2.8).

&lt;div&gt;$$\begin{split}
f_T(t)\; &amp;=\; \sum _{k=1}^\infty f_T(t \mid K=k)\; P[K=k] \\
         &amp;=\; \sum _{k=1}^\infty (\text{Eq. }2.54) (\text{Eq. }2.62) \\
         &amp;=\; \sum _{k=1}^\infty
              (\lambda _1 &#43; \lambda _2) e^{-(\lambda _1 &#43; \lambda _2)t}
              \frac {\{(\lambda _1 &#43; \lambda _2)t\}^{k-1}} {(k-1)!}\;
              \left(\frac {\lambda _2} {\lambda _1 &#43; \lambda _2} \right)^{k-1}
                    \frac {\lambda _1} {\lambda _1 &#43; \lambda _2} \\
         &amp;=\; \lambda _1 e^{-(\lambda _1 &#43; \lambda _2)t}\;
              \sum _{k=1}^\infty \frac {(\lambda _2 t)^{k-1}} {(k-1)!} \\
         &amp;=\; \lambda _1 e^{-(\lambda _1 &#43; \lambda _2)t}\;
              \sum _{k=0}^\infty \frac {(\lambda _2 t)^k} {k!} \\
         &amp;=\; \lambda _1 e^{-(\lambda _1 &#43; \lambda _2)t}\; e^{\lambda _2 t} \\
         &amp;=\; \lambda _1 e^{-\lambda _1 t}
\end{split}$$&lt;/div&gt;

{#{#HUGOSHORTCODE-1#}#}

Filtered Poisson process = Poisson process with rate `$\lambda p\; (=\lambda _1)$`
:   -   total occurrence rate `$\lambda = \lambda _1 &#43; \lambda _2$`
    -   acceptance rate (proportion of the focal event)
        `$p = \frac {\lambda _1} {\lambda _1 &#43; \lambda _2}$`

#### 2.2.2 Convolutions of Exponential Distributions

The sum of the waiting times of $n$ events:

If the rate does not change with each event ($\lambda _i = \lambda \text{ for all } i$),
:   → gamma-distributed (Eq. 2.54)

If the rate changes with each event ($\lambda _i \neq \lambda _j \text{ for } i \neq j$),
:   (e.g., in the study of genealogies, the rate of coalescence changes every time a coalescent event occurs)\
    → obtained by successive convolution of exponential distribution (Eq. 2.63, 2.64)

&lt;div&gt;$$\begin{split}
f_{T_1 &#43; T_2}(t)
   &amp;= \int _0^t f_{T_1}(s)\; f_{T_2}(t-s)ds \\
   &amp;= \int _0^t \lambda _1 e^{-\lambda _1 s}\; \lambda _2 e^{-\lambda _2 (t-s)}ds \\
   &amp;= \lambda _1 \lambda _2 e^{-\lambda _2 t} \int _0^t e^{-(\lambda _1 -\lambda _2)s}ds \\
   &amp;= \lambda _1 \lambda _2 e^{-\lambda _2 t}
      \left[-\frac 1{\lambda _1 - \lambda _2} e^{-(\lambda _1 -\lambda _2)s} \right]_0^t \\
   &amp;= \frac {\lambda _1} {\lambda _1 - \lambda _2} \lambda _2 e^{-\lambda _2 t}
      \left(1 - e^{-(\lambda _1 -\lambda _2)t} \right) \\
   &amp;= \frac {\lambda _1} {\lambda _1 - \lambda _2} \lambda _2 e^{-\lambda _2 t} &#43;
      \frac {\lambda _2} {\lambda _2 - \lambda _1} \lambda _1 e^{-\lambda _1 t} \\
   &amp;= \frac {\lambda _1} {\lambda _1 - \lambda _2} f_{T_2}(t) &#43;
      \frac {\lambda _2} {\lambda _2 - \lambda _1} f_{T_1}(t) \\
  (&amp;= \text{weighted sum of the original distributions})\\[1ex]
f_{T_1 &#43; T_2 &#43; T_3}(t)
   &amp;= \int _0^t f_{T_1 &#43; T_2}(s)\; f_{T_3}(t-s)ds \\
   &amp;= \frac {\lambda _2} {\lambda _2 - \lambda _1}
      \frac {\lambda _3} {\lambda _3 - \lambda _1} \lambda _1 e^{-\lambda _1 t} &#43;
      \frac {\lambda _3} {\lambda _3 - \lambda _2}
      \frac {\lambda _1} {\lambda _1 - \lambda _2} \lambda _2 e^{-\lambda _2 t} &#43;
      \frac {\lambda _1} {\lambda _1 - \lambda _3}
      \frac {\lambda _2} {\lambda _2 - \lambda _3} \lambda _3 e^{-\lambda _3 t} \\[1ex]
f_{T_1 &#43; T_2 &#43; T_3 &#43; T_4}(t) &amp;= \cdots \\
   &amp;\;\vdots \\
f_{\sum _{i=1}^n T_i}(t)
   &amp;= \sum_{i=1}^n \lambda _i e^{-\lambda _i t}
      \prod _{j=1,\;j \neq i} \frac {\lambda _j} {\lambda _j - \lambda _i}
\end{split}$$&lt;/div&gt;

We will use this to obtain the distribution of the total waiting time
to the MRCA of the entire samples (Eq. 3.27)

</code></pre>
</aside>

<footer>(ɔ) 2008 Watal M. Iwasaki</footer>
</div>

<script src="/js/highlight.pack.js"></script>
<script>
hljs.configure({languages: ["sh","c++","python","r","tex"]});
hljs.initHighlightingOnLoad();
</script>
</body>
</html>

